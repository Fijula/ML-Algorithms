
ğŸ” What It Is:
A probabilistic classifier based on Bayesâ€™ Theorem.
Assumes all features are independent (naive).
Uses probabilities of features belonging to classes.
ğŸ’¡ Real-Life Example:
Email spam detection: If an email contains â€œfreeâ€, â€œmoneyâ€, â€œwinâ€, itâ€™s probably spam.
âœ… Python Code:
from sklearn.naive_bayes import GaussianNB

X = [[1,20],[2,21],[3,22]]
y = [0,1,0]

model = GaussianNB()
model.fit(X, y)

print(model.predict([[2, 20]]))  # Predicts class
ğŸ§® Diagram (Simplified Logic):
P(Class=Spam | â€œFreeâ€) = High
P(Class=Not Spam | â€œFreeâ€) = Low
â†’ Predict: Spam
âœ… Pros:
Fast and efficient
Great for text classification (spam, sentiment)
Works well with high-dimensional data
âŒ Cons:
Assumes features are independent (rare in real life)
Doesnâ€™t handle feature interaction well
