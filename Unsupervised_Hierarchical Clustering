What it is:

Builds a tree (dendrogram) by progressively merging or splitting groups.
No need to predefine the number of clusters.
Can use "top-down" or "bottom-up" approaches.
ğŸ“ˆ Diagram:

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚               â”‚
 â”Œâ”€â”€â”´â”€â”€â”         â”Œâ”€â”€â”´â”€â”€â”
A     B         C     D
ğŸŒ Real-life Example:

Creating a family tree: grouping people based on ancestry.
Organizing documents by similarity.
ğŸ‘¨â€ğŸ’» Code:

from scipy.cluster.hierarchy import dendrogram, linkage
import matplotlib.pyplot as plt

data = [[1], [2], [3], [10], [11], [12]]
linked = linkage(data, 'single')
dendrogram(linked)
plt.show()
ğŸ”¹ 3. DBSCAN (Density-Based Spatial Clustering of Applications with Noise)
ğŸ” What it is:

Finds clusters based on density (many nearby points).
Labels low-density points as noise/outliers.
No need to predefine number of clusters.
ğŸ“ˆ Diagram:

    Cluster 1     Noise    Cluster 2
    â— â— â— â—        x       â—¯ â—¯ â—¯ â—¯
ğŸŒ Real-life Example:

Detecting anomalies in network traffic.
Identifying groups of friends at school; "loners" are outliers.
ğŸ‘¨â€ğŸ’» Code:

from sklearn.cluster import DBSCAN

X = [[1], [2], [3], [10], [11], [12], [100]]  # 100 is an outlier
model = DBSCAN(eps=2)
model.fit(X)

print("Labels:", model.labels_)  # [-1 means outlier]
